var EventEmitter = require('sk/core/events').EventEmitter,
models = require('../../models'),
SmartCacher        = require('sk/core/smart').smart.Cacher,
OverUsedImageCacher = require('./image').OverUsedImageCacher,
getImageSize = require('../getImageSize'),
utils = require('sk/node/utils'),
Url = require('url'),
findLocation  = require('psk/node/io/net').findLocation,
Queue = require('sk/core/queue').Queue,
Discovery = require('./discovery'),
crypto = require('crypto'),
cashew = require('cashew'),
logger = require('winston').loggers.get('feeds.stream.core'),
sprintf = require('sprintf').sprintf,
dumpOld = require('../../utils/dumpOld');


//the controls all the items that have been either auto-promoted, or promoted by individual
//users. 

//ME 2012 - this is fucking spaghetti.

var PromotionsDelegate = function(plugin, dbManager, c_feedData, PromotedItemsModel)
{                                   
	var self = this,
	router = plugin.router,    
	params = plugin.appParams.promotions || {},
	searchClient,
	keyIds  = {},
	REDUCE_PROMOTIONS_INTERVAL = 10000,//map-reduce NEW promotions every X seconds
	NUM_AUGMENT_CONTENT        = 1000,//N items that go out to each service and self promote themselves. 
	GOOD_DESC_SIZE = 500,//if the article is fewer characters than this number, then go out and FIND more content on the page
	MIN_AUGMENTED_DATA = 1, //updated. let's do everything.
	MAX_FILTER_SEARCH_AGAINST = 20, //MAX feeds to search against for a given group. this is to prevent queries from becoming grosely large
	MAX_PROMO_LOAD_AGE = 1000*3600*24*7, //7 days 
	MIN_LOAD_LIKES_TTL = 60 * 30 * 1000,
	MIN_IMAGE_SIZE = 50,//remove anything smaller
	MAX_AUGMENT_TRIES = 4,
	MAX_PROMO_AGE_DAYS = params.maxAge || 0,
	idGen = cashew.register('promoted') //max tries before we stop trying to augment a particular item. items are only re-augmented if they failed the first time - most likely because of
	//server issues 
	
	new EventEmitter().copyTo(this);
	
	this.addPromotable = function(post, likes, dislikes)
	{   
		if(!post.link) return;                     
		                                
		logger.verbose('adding promotable item job');                  
		router.push('thyme/job', { _id: post._id, queue: process.env.SLAVE_APP_NAME, path: 'add/next/promotion', data: post, label: post.link });
	}
	
	this.getPromotion = function(linkOrId, callback)
	{
		var search = {};
		
		if(linkOrId.indexOf('://') > -1)
		{
			search.link = linkOrId;
		}
		else
		{
			search._id = linkOrId;
		}

		
		PromotedItemsModel.findOne(search, function (err, item)
		{
			callback(item);
		})
	}

	this.hot = function(feeds, options, callback)
	{   
		findPromotions(feeds, options, ['heat', -1], callback);
	}   
	
	this.new = function(feeds, options, callback)
	{
		findPromotions(feeds, options, ['createdAt', -1], callback);
	}
	
	this.top = function(feeds, options, callback)
	{                                         
		if(!callback)
		{
			callback = options;
			options = {};
		}                

		time  	  = options.time || 'year',
		createdAt = new Date().getTime();

		switch(time)
		{
			case 'day':                      
			createdAt -= 1000 * 60 * 60 * 24;  
			break;
			case 'week':                      
			createdAt -= 1000 * 60 * 60 * 24 * 7; 
			break;
			case 'month':                      
			createdAt -= 1000 * 60 * 60 * 24 * 30; 
			break;
			case 'year':     
			createdAt -= 1000 * 60 * 60 * 24 * 365;  
			break;
			case 'all': 
			createdAt = 0;
			break;
			default:
			time = 'day';
			break;
		}	      
		if(!options.search) options.search = {};
		
		
		options.search = {createdAt:{$gt:new Date(createdAt)}};
		
		
		//useful for filtering new content that may not be important, or worth reading
		if(options.minScore)
		{
			options.search.score = {$gt:Number(options.minScore) || 1};//{likes:{$gt:options.minLikes}}
		}
		
		findPromotions(feeds,options,['score',options.order == 'ascending' ? 1 : -1],callback);                   
	} 


	function findPromotions(feeds, options, sort, callback)
	{
		if(!callback)
		{
			callback = options;
			options = {};
		}                      
		
		var page  = options.page || 0,  
		count 	  = Math.min(options.count || 30, 100); 
		
		var search = options.search || {};

		if(feeds)
		{
			search.feeds = { $in: feeds };
		}



		if(Number(options.beforeDate))
		{
			search.createdAt = {$lt: new Date(Number(options.beforeDate)) };
		}

		if(Number(options.afterDate))
		{
			search.createdAt = search.createdAt || {};
			search.createdAt.$gt = new Date(Number(options.afterDate));
		}


		if(options.returnCount)
		{
			return PromotedItemsModel.count(search, callback);
		}

		if(options.media)
		{
			search['media.type'] = {$in : options.media.split(/\s+OR\s+/) };
		}
		
		if(options.site)
		{
			search.site = options.site;
		}

		if(options.service)
		{
			search.service = options.service;
		}
		
		var ops = { skip: page * count, limit: count, sort: [sort] };

		
		var cacheKey = JSON.stringify({search: search, ops: ops, filter: options.filter });
		
		
		function onData(data, cache)
		{
			callback(false, data);
		}
		
		
		function searchPromos()
		{
			function onFilteredSearch(result)
			{
				
				//if there's filtered data, don't fetch if from mongo
				if(result) return onData(result);

				//otherwise it's unfiltered...
				PromotedItemsModel.collection.find(search, ops ,function(err, cursor)
				{
					cursor.toArray(function(err, items)
					{
						onData(items);
					})
				})
			}
			
			
			if(options.filter && searchClient)
			{
				var filter = options.filter,
					andFeeds = '';

				var qs = '(' + filter + ')';
				
				//this can become grosely complex if a group has say... 200 feeds. not worth it. If the group is less than N feeds
				//then we can search against the group
				if(feeds && feeds.length < MAX_FILTER_SEARCH_AGAINST)
				{
					// feeds = feeds.splice(0,20);
					
					for(var i = feeds.length; i--;)
					{
						feeds[i] = 'feeds:' + feeds[i].replace(/:/g,'\\:');
					}
					
				
					qs += ' AND ('+feeds.join(' OR ')+')';
				}

				if(search.site)
				{
					qs += ' AND site:' + search.site;
				}

				if(search.service)
				{
					qs += ' AND service:' + search.service;
				}

				/*if(search.media)
				{ //todo
					qs += ' AND '
				}*/
								
				searchClient.search({ q: qs }, onFilteredSearch);
			}
			else
			{
				onFilteredSearch();
			}
			
		}
		
		return searchPromos();
	}

	function getCommentsHandler(req, res)
	{
		res.end({
			type: 'article',
			incrementComments: function(target, n)
			{
				PromotedItemsModel.findOne({ _id : target }, function(err, item)
				{
					if(!item) return;
						
					PromotedItemsModel.collection.update({ _id: target }, {$inc : { numComments: n }});
				});
				
			}
		});
		
	}

	function getSearchClient()
	{                               
		
		return searchClient = {
			name: params.ftsIndex || 'promotions',
			init: function(callbacks)
			{
				var i = 0;
				
				self.addListener('newPromotion', function(data)
				{
					var d = data.doc || data;
					
					if(d.feeds) d.feeds = d.feeds.join(' ');
					
					['likes','dislikes','heat','score','nextUpdate'].forEach(function(property)
					{
						delete d[property];
					})

					
					callbacks.addSearchable(d);
				});
			}
		};
	}


	/*var hasPromoCacher = new SmartCacher(100);
	
	function cacheFeed(url, feedId, ignoreSet)
	{
		var uid = url+feedId;
		
		if(hasPromoCacher.get(uid)) return false;

		hasPromoCacher.set(uid, 1, 60 * 1000); //save for 1 minute
		return true;
	}*/


	function findPromotion(req, res)
	{
		self.getPromotion(pull.data, function(err, result)
		{
			res.end(result);
		});
	}

	function initSlave()
	{

		function addNextPromotion(req, res)
		{                                               
			var data = this.flattenData(),
			dataId = data._id;

			if(!data.link/* || !cacheFeed(data.link, data.feedId)*/)
			{
				logger.verbose(data.link+' was found in mem, removing.');
				return res.end();
			}
			
			var request, finished = false;
			
			function finish(fail, ttl)
			{
				if(finished) return;
				finished = true;


				res.end(ttl ? { sendAt: new Date().getTime()+Math.max(4000,ttl || 0) } : null );
			}
			
			//this will be cached for us
			request = findLocation(data.link, function (url)
			{
				
				if(url && url.error) logger.error('url '+data.link+' is null when it shouldn\'t be');
				
				//something went wrong. Socket hang up most likely
				if(!url || url.error) return finish(true,3600 * 1000 * 4);
				
				//if the search was killed, too fucking bad. if the link has changed, check if it's cached. if it is, then we don't want to handle it again
				//now do we?
				if(finished || (data.link != url/* && !cacheFeed(url, data.feedId)*/))
				{
					logger.verbose(data.link + ' was found in mem, removing');
					return finish();
				}
				
				function addFeedToPromotion(data, promotion)
				{
					if(promotion)
					{
						logger.verbose('updating promo ' + url + ' to contain feed id: ' + data.feedId);
					
						if(promotion.feeds.indexOf(data.feedId) == -1) 
						{
							promotion.feeds.push(data.feedId);
						}
					
						promotion.save();
						return true;
					}
					return false;
				}
				
				PromotedItemsModel.findOne({ link: url }, function (err, promotion)
				{
					if(addFeedToPromotion(data, promotion)) return finish();
				
					//let's update the URL incase it's a short url... Also, let's re-augment it shall we?
					if(data.link != url)
					{
						data.link = url;

						//need to run it through the augmentor again because the expanded url could be a youtube link, twitpic, jpeg. etc..
						plugin.loader.standardizer.standardizeFeedItem(data);
					}
					
					
					
					
					function updateData(toInsert)
					{
						var search = {},
							feedId = toInsert.feedId;
						
						//this is needed so we can search against it
						toInsert.likes = toInsert.dislikes = toInsert.heat = toInsert.score = 0;
						
						var urlInfo = Url.parse(url),
							domainParts = (urlInfo.hostname || '').split('.');

						//remove
						if(domainParts[0] == 'www') domainParts.shift();

						//set the site so we can search against it
						toInsert.site = domainParts.join('.');
						
						//check if the UID is set, or use the link. (UID is needed especially for items such as youtube)
						//yes, yes... there are 16^32 possibilites with md5, but I just feel more comfortable using the domain as part
						//of the uid.
						search._id   = idGen.hash(utils.base64.encode(domainParts.shift()).toLowerCase().replace(/[^a-z0-9]/g,'')+'-'+ (toInsert.uid || toInsert.link));
												
						//this stuff is useless
						utils.deleteKeys(['feedId','augment','uid','_id'], toInsert);
						
						PromotedItemsModel.findOne(search, function(err, promotion)
						{
							//we want to update incase a link from a different feed is inserted as the same time as another. e.g: engadget rss vs twitter engadget link.
							//yeah yeah, it's more f'n overhead. maybe we cache? I think that's a good solution, but this works for now. When optimiziln' comes around,
							//we'll swap this shit out. Word.
							if(addFeedToPromotion({feedId: feedId}, promotion)) return;
                                                     
							
							toInsert.createdAt = new Date(Number(toInsert.createdAt));
							

							toInsert._id = search._id;
							toInsert.feeds = [feedId];
							// toInsert.nextUpdate = new Date();
							
							//retain the original message of the post so we have some context
							toInsert.message = data.text;        
							                       
							
							promotion = new PromotedItemsModel(toInsert);
							promotion.save();
							

							var callAt = new Date(),
								timeDiff = callAt.getTime() - toInsert.createdAt.getTime();


							//make sure the item is NOT new before checking promos
							callAt.setTime(callAt.getTime() + Math.min(3600 * 1000 - timeDiff, 0));

							logger.verbose('adding get promotion influence job');
							//new Date(new Date().getTime() - 3600 * 24 * 7 * 1000), $lt: new Date(new Date().getTime() - 3600 * 1000)
							//search for influence on social networks
							router.push('thyme/job', { _id: toInsert._id, queue: process.env.APP_NAME, path: 'get/next/promotion/influence', data: toInsert, label: toInsert.link, callAt: callAt });
							router.push('thyme/job', { _id: toInsert._id, queue: process.env.APP_NAME, path: 'clean/next/promotion/media', label: toInsert.link, data: toInsert });
						});
					
						finish();
					}
					
					
					function onAugmented(err,toUpdate)
					{
							//if the item is NOT augmented, and we've tried twice already, then set to augmented
							//this will only pass is other people are talking about it... we WANT items to be augmented... we give them another chance
							//since the server could be down, or slow
							
							
							//not augmented? It's failed, so let's skip it, up to N tries
							if(!toUpdate.augmented) return finish(true);
							
							
							
							//augmented data? let's set the new data 
							var newData = {label: betterText(toUpdate.label, data.label, 5),
								 		
								          //this combines the previous, with the new
										  media: toUpdate.media, 
										
										  //the new text, ONLY if the old blurb doesn't suffice. NOTE
										  //THIS NEEDS TO STAY COMMENTED UNTIL WE COMPLETELY REBUILD THE READLY SCRIPT. it uses parts of readability
										  //which is licensed only under apache. 
										  text: toUpdate.text || data.text,
										
										  //either the title of the article, or the link - (md5 hash)
										  _id:toUpdate.uid};

							
							//overwrite the old with the new
							for(var i in newData) data[i] = newData[i];
								
							updateData(data)
					}
					
					
					//if we DON'T want to augment, or the data is already augmented, then we're gonna go ahead ahd insert...
					if(data.augment == false)
					{
						updateData(data);
					}
					else
					{
						augment(data, onAugmented)
					}
				})
			});
		}

		//goes out, and augments HOT items only
		function augment(promo, callback)
		{          

			var augmentor = self.augmentData;

			logger.verbose('augmenting article');


			augmentor(promo, promo.link, function (err, data)
			{
				data = data || {};

				//flag the "augmented" bool value so we dont' get back to this item. Also makes it searchable incase we want to show ONLY
				//augmented data
				data.augmented = err ? false : true;

				//uid MUST be present
				if(!data.uid) data.uid = idGen.hash(promo.link);


				if(err) return callback(err, data);


				var oldMedia = (promo.media || []).concat();

				//we need to combine the augmented media, with the old media since the old media still contains stuff like urls, which need to get
				//replaced client-side 

				var omlinks = {},
					useable = [];

				
				for(i = oldMedia.length; i--;)
				{    
					if(oldMedia[i].link)                 
					omlinks[oldMedia[i].link] = oldMedia[i];          

				}
				
				if(data.media)
				for(var i = data.media.length; i--;)
				{     
					if(data.media[i].link)
					if(!omlinks[data.media[i].link]) 
					{
						//since the media is scored, we want to RETAIN the order it came it, otherwise we'll get undesirable content
						useable.unshift(data.media[i])
					}     
				}    
				
				data.media = useable.concat(oldMedia);
				
				
				
				callback(false, data);
			});

		}

		function score(ups, downs)
		{
			return ups - downs;
		}
		
		function betterText(newText, oldText, margin)
		{
			if((newText || '').length - (oldText || '').length > margin) return newText;
			return oldText;
		}

		function heat(ups, downs, date)
		{
			var s = score(ups, downs);
			var order = Math.log(Math.max(Math.abs(s), 1), 10);// / Math.LN10;              
			var sign = s > 0 ? 1 : (s < 0 ? -1 : 0);                      
			var seconds = (date / 1000) - 1134028003;  
			return Math.round(order + sign * seconds / 45000, 7); 
		}

		function getNextPromotionInfluence(req, res)
		{
			var item = this.flattenData(),
			n = 0,
			
				//use the old details in case we need to skip a service
			details = item.promoDetails || {};
			
			
			function updateItem()
			{
				var totalLikes = 0,
					totalDislikes = 0

				
				for(var service in details)
				{
					var detail     = details[service];
					totalLikes    += (detail.likes    * detail.multiplier) || 0;
					totalDislikes += (detail.dislikes * detail.multiplier) || 0;
				}     
				       
				//used for finding the next time to load
				var likeChange = totalLikes-(item.likes || 0);
				
				
				//this MAY happen if we need to skip a service because it's down the but likelyhood of this actually happening
				//should be pretty slim.
				if(item.likes) totalLikes = Math.max(item.likes,totalLikes);
				if(item.dislikes) totalDislikes = Math.max(item.dislikes,totalDislikes);
				
				// console.log(item)
				//fucking shit. For some odd reason, dates are converted into integers (all of them).
				//could be something to do with converting JSON dates to numb ers...
				// if((typeof item.createdAt == 'number') || !item.createdAt.getTime)
				{	
					item.createdAt = new Date(Number(item.createdAt));
				}

				var now = new Date().getTime(),               
				    ageInMS = now-item.createdAt.getTime(),     
					numLoads = Math.max(1,item.loads || 0);    
					                           
				//if the change is zero, we don't want to set the ttl into oblivion. So if the post was made 20 hours ago, and this is the first load, and the
				//like-change is 0, the next post will be in 5 hours. second load, and change = 0, the load will be 10 hours.                         
				var ttl = (ageInMS*(numLoads*.5))/Math.max(likeChange,1);  
				             
				//make sure we're not loading it too often         
				ttl = Math.max(ttl,MIN_LOAD_LIKES_TTL);                      
				 
				logger.verbose('updating influence for '+item.link+' - change:' + likeChange + ' loads: ' + numLoads + ', next check: ' + utils.prettyDate(ttl) + ', age: ' + ageInMS);                       
				
				//let's update the promotion 
				var toUpdate = {
					likes: totalLikes
					,dislikes: totalDislikes
					,score: score(totalLikes, totalDislikes)
					,heat: heat(totalLikes,totalDislikes,item.createdAt.getTime())
					,promoDetails: details
				};                 
				
				if(isNaN(toUpdate.heat)) toUpdate.heat = 0;
                                            
				    
				
				
				PromotedItemsModel.collection.update({ link: item.link }, { $set: toUpdate }, function(err)
				{

					//item has to be older than N days old before we throw it back into the queue
					if(item.createdAt.getTime() > new Date(new Date().getTime() - 3600 * 24 * 7 * 1000).getTime())
					{
						for(var i in toUpdate) item[i] = toUpdate[i];

						res.end({ data: item, sendAt: new Date(now+ttl).getTime() });
					}
					else
					{
						res.end();
					}
				});   
				
			}

			var q = new Queue();
			
					
			var promoters = discovery.getPromotionFinders(item),
				nPromoters = promoters.length;
			
			function findLikes(next)
			{
				promoters.forEach( function (promoter)
				{
					logger.verbose(sprintf('finding promo influence on %s', promoter.service));

					promoter.find(item, function(likes, dislikes)
					{
						if(likes || dislikes)
						{
							if(!likes) likes = 0;
							if(!dislikes) dislikes = 0;   
							                             

							var dt = details[promoter.service] = {
								score: score(likes,dislikes),
								heat: heat(likes, dislikes, item.createdAt) || 0,
								likes: likes,
								dislikes: dislikes,
								multiplier : promoter.multiplier || 1
							}        
							
							if(isNaN(dt.heat)) dt.heat = 0;

							//record statistics on this particular item so we have analytics
							// promoGrowthStats.child(promoter.service).record(item.link, likes);
						}


						//are we done here? K let's wrap this up
						if(!(--nPromoters))
						{
							// updateItem();
							q.next();
						}
					})

				});
			}
			
			
			if(nPromoters)
			q.add(findLikes);
			
			q.add(updateItem);
			
			q.start();
		}

		var overUsedCacher = new OverUsedImageCacher(dbManager);


		function cleanNextPromotionMedia(req, res)
		{
			return res.end();

			/*var item = this.flattenData(),
			md = item.media,
				q = new Queue();  


			md.forEach(function(mdi, index)
			{
				if(mdi.type != 'image') return;

				var nexted = false;

				function removeImageMedia(err)
				{
					if(nexted) return;
					nexted = true;
					
					// clearTimeout(killTimeout);
					
					if(err) logger.verbose(sprintf('removing image %s', mdi.regular.link));
					
					item.media.splice(md.indexOf(mdi), 1);
					
					q.next();
				}

				q.add(function()
				{
					overUsedCacher.tryUsing(item.site, mdi.regular.link, function(useable)
					{                      

						if(!useable) return removeImageMedia();


						var w = mdi.regular.width || 0,
						h = mdi.regular.height || 0,
						r = Math.min(w,h) / Math.max(w,h); //for sanity check

						//if the width or height doesn't exist, or the ratio between w / height is rediculous, then get the image size    
						//ratio = off = probably a server-side iss        
						if(!w || !h || (r < .3))
						{                    
							getImageSize(mdi.regular.link, function(result)
							{
								if(nexted) return;
								
								if(!result || result.error)
								{
									return removeImageMedia(true);
								}
								else
								{
									mdi.regular.width = result.width;
									mdi.regular.height = result.height;
								}
								
								if(mdi.regular.width < MIN_IMAGE_SIZE || mdi.regular.width < MIN_IMAGE_SIZE)
								{
									logger.verbose(sprintf('The image %s is too small, removing.', mdi.regular.link));
									
									return removeImageMedia();
								}
								
								q.next();
							})
						}
						else
						{
							q.next();
						}
					});
				});
			
			});

			q.add(function()
			{
				item.media = md;
				
				PromotedItemsModel.collection.update({_id: item._id }, {$set: { media: md }}, function()
				{
				});	
		
				//PromotedItemsModel.collection.emitAdd(item);
				
				//notify that there's a new promotion
				self.emit('newPromotion', item);
 
				res.end();
			});
			
			q.start();*/
		}


		//public because this is overwritten
		this.augmentData = function(fbv, url, callback)
		{
			logger.warn('using default data augmentor');
			
			callback(true);
		}

		var discovery = new Discovery();

		
		router.on({
			'push -pull -hook thyme/ready': function()
			{
				logger.verbose('thyme is ready, adding worker info')                       
			                       
				this.from.push('thyme/worker', { queue: process.env.SLAVE_APP_NAME, path: 'add/next/promotion', num: 10 });
				this.from.push('thyme/worker', { queue: process.env.SLAVE_APP_NAME, path: 'get/next/promotion/influence', num: 10 });
				this.from.push('thyme/worker', { queue: process.env.SLAVE_APP_NAME, path: 'clean/next/promotion/media', num: 10 });
			},

			//adds a NEW promotion
			'pull -hook add/next/promotion': addNextPromotion,

			//checks for the promotion influence across an array of services: twitter, facebook, reddit
			'pull -hook get/next/promotion/influence': getNextPromotionInfluence,

			//cleans the promotion of any bad media (shitty images, dupes, etc.)
			'pull -hook clean/next/promotion/media': cleanNextPromotionMedia,


			'push -collect promotion/finder': discovery.addPromotionFinder,
		});
	}
	
	router.on({
		'pull comments/handler': getCommentsHandler,
		'collect search/client': getSearchClient,
		'pull find/promotion': findPromotion,
		'push -pull init/slave': initSlave,
		'push promote': this.addPromotable,
		'push -pull augmentor': function(augmentor)
		{
			logger.verbose('add default augmentor for stream');

			self.augmentData = augmentor;
		}
	});
	
	dumpOld(PromotedItemsModel, 'promotions', MAX_PROMO_AGE_DAYS);

	                       
} 

exports.PromotionsDelegate = PromotionsDelegate;